# Recommender System — MVP

## Что делаем
Делаем простой MVP рекомендательной системы для интернет‑магазина. Хотим увеличивать оборот за счёт релевантных товаров.
Главная тех. метрика в экспериментах: Precision@10 / Recall@10 для рекомендаций и AUC для модели покупки.

## Данные
Источник: Retail Rocket (`events`, `item_properties`, `category_tree`).
Объём: ~2.7M событий, ~1.4M пользователей, ~235k товаров.

## Признаки (features)
- События: `view`, `addtocart`, `transaction` (а также их счётчики по user–item).
- Время: день недели, час, «часть суток» (Night/Morning/Afternoon/Evening).
- Товары: топ‑20 свойств (включая `categoryid`, `available`) → one‑hot/счётчики.

## Валидация
Разбиваем по времени: train — до `2015‑07‑01`, test — после. Так не «подглядываем в будущее».

## Модели (кратко)
- **Baseline (Top‑N популярных)** → Precision@10 ≈ **0.0115**.  
- **LightFM (WARP)** → Precision@10 ≈ **0.0070**, Recall@10 ≈ **0.054**.  
- **XGBoost (классификация покупки)** → AUC ≈ **0.967**.  
Для MVP берём XGBoost: быстро, стабильно, даёт хороший AUC.

## REST API
Сервис принимает минимальные признаки и возвращает вероятность покупки.

### `POST /predict`
**Вход**:
```json
{"view": 3, "addtocart": 1}
```
**Ответ**:
```json
{"purchase_probability": 0.83}
```

### `GET /metrics`
Возвращает основную метрику качества модели (AUC):
```json
{"AUC": 0.9666}
```

### `GET /health`
Проверка, что сервис жив:
```json
{"status": "ok"}
```

## Как запустить

### В Docker
```bash
# локально собрать
docker build -t kotleha/recommender:latest .

# или стянуть готовый образ
# docker pull kotleha/recommender:latest

# запустить
docker run --rm -p 8000:8000 kotleha/recommender:latest
```

### Локально (без Docker)
```bash
pip install -r requirements.txt
python app.py
# сервис будет на http://localhost:8000
```

### Примеры запросов (curl)
```bash
curl http://localhost:8000/health

curl http://localhost:8000/metrics

curl -X POST http://localhost:8000/predict   -H "Content-Type: application/json"   -d '{"view": 3, "addtocart": 1}'
```

## Что ещё можно улучшить дальше

* **Добавить больше признаков про товары и людей**

  * Про товар: категория, бренд, «диапазон цены» (дешёвый/средний/дорогой), есть ли сейчас в наличии, новинка или нет.
  * Про пользователя: как давно что-то смотрел/покупал, какие категории любит чаще всего, средний чек.
  * Зачем: чем больше понятных сигналов, тем точнее модель «угадывает», что показать прямо сейчас.

* **Подтянуть «умные» рекомендатели и смешать подходы**

  * Посчитать похожесть товаров по истории просмотров/покупок (например, «люди, которые брали X, часто брали и Y»). Это можно сделать разными способами, суть одна — найти соседей каждому товару по поведению пользователей.
  * Сделать «гибрид»: смешиваем простые популярные товары + персональные рекомендации + похожие товары. Вес каждого блока подберём по валидации.
  * Зачем: один метод редко «тащит» во всех ситуациях. Смешивание даёт стабильный результат и перекрывает слабые места.

* **Подранжировать топ-N под витрину на главной**

  * У нас мало слотов (например, 3 карты). Берём длинный список кандидатов и упорядочиваем его с учётом:

    * вероятности клика/покупки,
    * наличия на складе,
    * разнообразия (не три одинаковых чайника),
    * маржи/приоритета бизнеса,
    * свежести (новинки).
  * Добавим простые правила: не советуем то, что пользователь уже купил недавно; не показываем недоступное; чередуем категории.
  * Зачем: «у кого выше — у того больше шансов быть купленным», поэтому порядок решает деньги.

* **Онлайн-метрики и A/B — когда пойдёт живой трафик**

  * Что меряем: клики, добавления в корзину, покупки, выручку на показ (и в среднем, и на пользователя).
  * Как тестируем: делим трафик на две группы, часть видит старый вариант, часть — новый. Смотрим разницу по метрикам.
  * Аккуратно: тест должен идти достаточно долго (чтобы было кому покупать), группы — достаточно большие и похожие, не меняем правила посреди теста.
  * После победы — выкатываем постепенно (не сразу на 100%), следим, чтобы качество не «просело».
